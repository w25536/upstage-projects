"""
Analysis Path Nodes

ë²„ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì°¨íŠ¸ íƒ€ì…ì„ ì„ íƒí•œ í›„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œë“¤
"""
import json
import os
from analytics.types.state_types import AnalyticsState
from config import build_chat_model
from langchain_core.messages import SystemMessage


def get_bus_data(state: AnalyticsState):
    """
    ë²„ìŠ¤ ë°ì´í„° ë¡œë“œ (LangGraph Node)

    - ìŠ¹í•˜ì°¨ì •ë³´.json
    - í†µê·¼ìˆ˜ë‹¹.json

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ì˜ ìƒíƒœ

    Returns:
        dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ {"transport_data": "...", "commute_allowance_data": "..."}
    """
    try:
        # íŒŒì¼ ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))

        transport_path = os.path.join(project_root, "data", "ìŠ¹í•˜ì°¨ì •ë³´.json")
        commute_path = os.path.join(project_root, "data", "í†µê·¼ìˆ˜ë‹¹.json")

        print(f"ğŸ“‚ Loading transport data from: {transport_path}")
        print(f"ğŸ“‚ Loading commute data from: {commute_path}")

        # ìŠ¹í•˜ì°¨ ì •ë³´ ë¡œë“œ
        with open(transport_path, 'r', encoding='utf-8') as f:
            transport_data = json.load(f)

        # í†µê·¼ ìˆ˜ë‹¹ ë¡œë“œ
        with open(commute_path, 'r', encoding='utf-8') as f:
            commute_data = json.load(f)

        print(f"âœ… ìŠ¹í•˜ì°¨ ì •ë³´ {len(transport_data)}ê±´ ë¡œë“œ ì™„ë£Œ")
        print(f"âœ… í†µê·¼ ìˆ˜ë‹¹ ì •ë³´ {len(commute_data)}ê±´ ë¡œë“œ ì™„ë£Œ")

        return {
            "transport_data": json.dumps(transport_data, ensure_ascii=False),
            "commute_allowance_data": json.dumps(commute_data, ensure_ascii=False)
        }
    except Exception as e:
        error_msg = f"âŒ ë²„ìŠ¤ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        return {
            "transport_data": "[]",
            "commute_allowance_data": "[]"
        }


def chart_type_selector(state: AnalyticsState):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ì í•©í•œ ì°¨íŠ¸ íƒ€ì… ì„ íƒ (LangGraph Node)

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ì˜ ìƒíƒœ

    Returns:
        dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ {"chart_type": "line_chart" | "bar_chart" | "table" | "text_summary"}

    Chart Types:
    - line_chart: ì‹œê³„ì—´ ì¶”ì´, ë³€í™” ë¶„ì„
    - bar_chart: ë¹„êµ, ìˆœìœ„, ë…¸ì„ ë³„ ë¹„êµ
    - table: ìƒì„¸ ë°ì´í„°, ì „ì²´ ëª©ë¡
    - text_summary: ìš”ì•½, ì„¤ëª…
    """
    user_message = state["messages"][-1]
    user_question = user_message.content if hasattr(user_message, 'content') else str(user_message)

    system_prompt = """
ë‹¹ì‹ ì€ ì°¨íŠ¸ íƒ€ì… ì„ íƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì°¨íŠ¸ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”.

ì„ íƒ ê°€ëŠ¥í•œ ì°¨íŠ¸ íƒ€ì…:
1. **line_chart**: ì‹œê³„ì—´ ì¶”ì´, ë³€í™”, íŠ¸ë Œë“œ ë¶„ì„
   - í‚¤ì›Œë“œ: "ì¶”ì´", "ë³€í™”", "ì›”ë³„", "ì‹œê°„ë³„", "íŠ¸ë Œë“œ"
   - ì˜ˆì‹œ: "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜"

2. **bar_chart**: ë¹„êµ, ìˆœìœ„, ë…¸ì„ ë³„ ë¹„êµ
   - í‚¤ì›Œë“œ: "ë¹„êµ", "ë…¸ì„ ë³„", "ìˆœìœ„", "ìƒìœ„", "í•˜ìœ„"
   - ì˜ˆì‹œ: "ë…¸ì„ ë³„ ìˆ˜ìµë¥  ë¹„êµí•´ì¤˜"

3. **table**: ìƒì„¸ ë°ì´í„°, ì „ì²´ ëª©ë¡
   - í‚¤ì›Œë“œ: "ìƒì„¸", "ëª©ë¡", "ì „ì²´", "ë°ì´í„°"
   - ì˜ˆì‹œ: "ì „ì²´ ë…¸ì„  ë°ì´í„° ë³´ì—¬ì¤˜"

4. **text_summary**: ìš”ì•½, ì„¤ëª…, ë¶„ì„ ê²°ê³¼
   - í‚¤ì›Œë“œ: "ìš”ì•½", "ì„¤ëª…", "ë¶„ì„ ê²°ê³¼"
   - ì˜ˆì‹œ: "ì•¼ê°„ ìˆ˜ë‹¹ ë¶„ì„ ê²°ê³¼ ìš”ì•½í•´ì¤˜"

ì‘ë‹µ: ì°¨íŠ¸ íƒ€ì…ë§Œ ì˜ì–´ë¡œ ì¶œë ¥ (ì¶”ê°€ ì„¤ëª… ê¸ˆì§€)
ì¶œë ¥ ì˜ˆì‹œ: line_chart
"""

    messages = [
        SystemMessage(content=system_prompt),
        user_message
    ]

    # LLM í˜¸ì¶œ
    llm = build_chat_model(temperature=0.3)
    response = llm.invoke(messages)

    chart_type = response.content.strip()

    # ìœ íš¨ì„± ê²€ì¦
    valid_types = ["line_chart", "bar_chart", "table", "text_summary"]
    if chart_type not in valid_types:
        print(f"âš ï¸  Invalid chart type: {chart_type}, defaulting to text_summary")
        chart_type = "text_summary"

    print(f"ğŸ“Š Chart Type Selected: {chart_type}")

    return {
        "chart_type": chart_type,
        "messages": state["messages"] + [response]
    }


def generate_analytic(state: AnalyticsState):
    """
    Solar Pro2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ë° ì°¨íŠ¸ ë°ì´í„° ìƒì„± (LangGraph Node)

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ì˜ ìƒíƒœ

    Returns:
        dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ {"chart_data": {...}, "analysis_result": "...", "messages": [...]}
    """
    user_question = state["messages"][0].content if hasattr(state["messages"][0], 'content') else str(state["messages"][0])
    chart_type = state.get("chart_type", "text_summary")
    transport_data = state.get("transport_data", "")
    commute_data = state.get("commute_allowance_data", "")

    print(f"ğŸ”¬ Generating analytics for: {chart_type}")

    # ì°¨íŠ¸ë³„ output format ì •ì˜
    output_formats = {
        "line_chart": """
{
    "chart_data": {
        "labels": ["January", "February", "March", ...],
        "datasets": [{
            "label": "Dataset Label",
            "data": [65, 59, 80, ...],
            "borderColor": "rgb(75, 192, 192)",
            "tension": 0.1
        }]
    },
    "insights": [
        "1ì›”ë¶€í„° 3ì›”ê¹Œì§€ ë°ì´í„°ê°€ ì§€ì†ì ìœ¼ë¡œ ìƒìŠ¹í•˜ëŠ” ì¶”ì„¸ë¥¼ ë³´ì´ë©°, íŠ¹íˆ 2ì›”ì— ê°€ì¥ í° ì¦ê°€í­ì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.",
        "ì „ì²´ ê¸°ê°„ ë™ì•ˆ í‰ê·  70 ìˆ˜ì¤€ì„ ìœ ì§€í•˜ê³  ìˆìœ¼ë©°, ê³„ì ˆì  ë³€ë™ì„±ì´ ê´€ì°°ë©ë‹ˆë‹¤.",
        "í–¥í›„ ì´ëŸ¬í•œ ìƒìŠ¹ ì¶”ì„¸ê°€ ê³„ì†ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ë©°, 4ì›”ì—ëŠ” 85ë¥¼ ë„˜ì–´ì„¤ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
    ],
    "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
}
        """,
        "bar_chart": """
{
    "chart_data": {
        "labels": ["ë…¸ì„ 1", "ë…¸ì„ 2", ...],
        "datasets": [{
            "label": "ìš´í–‰ë‹¨ê°€",
            "data": [73000, 68000, ...],
            "backgroundColor": "rgba(59, 130, 246, 0.6)",
            "borderColor": "rgb(59, 130, 246)",
            "borderWidth": 1
        }]
    },
    "insights": [
        "ì¶œê·¼1í˜¸ ë…¸ì„ ì´ 73,000ì›ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ìš´í–‰ë‹¨ê°€ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°, ì´ëŠ” í‰ê·  ëŒ€ë¹„ ì•½ 15% ë†’ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤.",
        "ë…¸ì„ ë³„ ìš´í–‰ë‹¨ê°€ í¸ì°¨ê°€ í¬ê²Œ ë‚˜íƒ€ë‚˜ê³  ìˆìœ¼ë©°, ê°€ì¥ ë†’ì€ ë…¸ì„ ê³¼ ë‚®ì€ ë…¸ì„  ê°„ ì•½ 20,000ì›ì˜ ì°¨ì´ë¥¼ ë³´ì…ë‹ˆë‹¤.",
        "ìš´í–‰ë‹¨ê°€ê°€ ë†’ì€ ë…¸ì„ ë“¤ì€ ì£¼ë¡œ ì¥ê±°ë¦¬ ìš´í–‰ êµ¬ê°„ì„ í¬í•¨í•˜ê³  ìˆì–´ ì—°ë£Œë¹„ì™€ ì‹œê°„ ë¹„ìš©ì´ ë§ì´ ë°œìƒí•˜ëŠ” ê²ƒìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤."
    ],
    "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
}
        """,
        "table": """
{
    "chart_data": {
        "columns": ["ë…¸ì„ ëª…", "ìš´í–‰ë‹¨ê°€", "ì§€ê¸‰ìˆ˜ë‹¹"],
        "rows": [
            ["ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸", 73000, 10000],
            ["ì¶œê·¼2í˜¸-í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›", 68000, 10000],
            ...
        ]
    },
    "insights": [
        "ì „ì²´ 8ê°œ ë…¸ì„  ì¤‘ ì¶œí‡´ê·¼ ë…¸ì„ ì´ 6ê°œë¡œ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•˜ë©°, ëª¨ë“  ë…¸ì„ ì˜ ì§€ê¸‰ìˆ˜ë‹¹ì€ ë™ì¼í•˜ê²Œ 10,000ì›ìœ¼ë¡œ ì±…ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
        "ìš´í–‰ë‹¨ê°€ëŠ” ë…¸ì„ ì˜ ê±°ë¦¬ì™€ ì†Œìš” ì‹œê°„ì— ë¹„ë¡€í•˜ì—¬ ì±…ì •ë˜ë©°, ìµœì†Œ 53,000ì›ë¶€í„° ìµœëŒ€ 73,000ì›ê¹Œì§€ ë¶„í¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "í‰ê·  ìš´í–‰ë‹¨ê°€ëŠ” ì•½ 65,000ì› ìˆ˜ì¤€ì´ë©°, ì¶œê·¼ ë…¸ì„ ì´ í‡´ê·¼ ë…¸ì„ ë³´ë‹¤ í‰ê· ì ìœ¼ë¡œ ì•½ 5,000ì› ë” ë†’ì€ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤."
    ],
    "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
}
        """,
        "text_summary": """
{
    "chart_data": null,
    "insights": [
        "ì „ì²´ ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼, ì£¼ìš” íŒ¨í„´ê³¼ íŠ¸ë Œë“œê°€ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚¬ìœ¼ë©° ì˜ˆìƒ ë²”ìœ„ ë‚´ì—ì„œ ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤.",
        "íŠ¹ì • êµ¬ê°„ì—ì„œ ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì—ˆìœ¼ë‚˜ ì „ì²´ì ì¸ ë°ì´í„° í’ˆì§ˆì€ ì–‘í˜¸í•˜ë©°, ì¶”ê°€ì ì¸ ì¡°ì‚¬ê°€ í•„ìš”í•œ ë¶€ë¶„ì€ ì œí•œì ì…ë‹ˆë‹¤.",
        "í–¥í›„ ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ í†µí•´ ì¶”ì„¸ ë³€í™”ë¥¼ ê°ì§€í•˜ê³ , í•„ìš”ì‹œ ê°œì„  ì¡°ì¹˜ë¥¼ ì·¨í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤."
    ],
    "reason": "ìƒì„¸ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸"
}
        """
    }

    system_prompt = f"""
êµí†µ ë°ì´í„°: {transport_data}

í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°: {commute_data}

ì‚¬ìš©ì ì§ˆë¬¸: {user_question}
ì„ íƒëœ ì°¨íŠ¸: {chart_type}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
```json ê°ì‹¸ì§€ ë§ê³  ìˆœìˆ˜ JSONë§Œ ì¶œë ¥.

ì¤‘ìš” ì§€ì¹¨:
1. insightsëŠ” ë°˜ë“œì‹œ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš” (ì£¼ì–´, ì„œìˆ ì–´ í¬í•¨).
2. ê° insightëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë¶„ì„ ë‚´ìš©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
3. insightsëŠ” 3ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ë¬¸ì¥ì€ ë§ˆì¹¨í‘œë¡œ ëë‚©ë‹ˆë‹¤.
4. "í•µì‹¬ í†µì°° 1:", "â€¢" ê°™ì€ ë¶ˆë¦¿ í¬ì¸íŠ¸ë‚˜ ë²ˆí˜¸ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

Output Format:
{output_formats[chart_type]}
"""

    # Solar Pro2 LLM í˜¸ì¶œ
    llm = build_chat_model(model="solar-pro2", temperature=0.5)
    response = llm.invoke([SystemMessage(content=system_prompt)])

    try:
        # JSON íŒŒì‹±
        content = response.content.strip()

        # ```json ë¸”ë¡ ì œê±°
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        elif content.startswith("```"):
            content = content.replace("```", "").strip()

        result = json.loads(content)

        print(f"âœ… ë¶„ì„ ì™„ë£Œ")
        print(f"   - insights: {len(result.get('insights', []))}ê°œ")

        return {
            "chart_data": result.get("chart_data"),
            "analysis_result": result.get("reason", ""),
            "insights": result.get("insights", []),
            "messages": state["messages"] + [response]
        }
    except json.JSONDecodeError as e:
        print(f"âš ï¸  ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        print(f"   Raw content: {response.content[:200]}")
        return {
            "analysis_result": response.content,
            "messages": state["messages"] + [response]
        }
