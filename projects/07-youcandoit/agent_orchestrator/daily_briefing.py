import os
import json
import torch
import asyncio
from datetime import datetime
from pathlib import Path
from model import load_model
from mcp_server.daily_briefing_collector import collect_daily_briefing_data  

# 1. ëª¨ë¸ ë¡œë“œ
tokenizer, model = load_model()

def create_briefing_prompt(data):
    emails = data['data']['gmail'].get('emails', [])
    slack_mentions = data['data']['slack'].get('mentions', [])
    notion_tasks = data['data']['notion'].get('tasks', [])

    dt = datetime.fromisoformat(data['timestamp'].split("+")[0])
    date_str = dt.strftime('%Yë…„ %mì›” %dì¼')

    # í”„ë¡¬í”„íŠ¸ ì•ˆì—ì„œëŠ” ì´ëª¨ì§€ ìœ ì§€
    prompt = f"""You are an AI assistant creating a daily briefing in Korean.

DATA ({date_str}):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“§ EMAILS ({len(emails)}):
"""
    for i, email in enumerate(emails, 1):
        prompt += f"{i}. [{email['subject']}] from {email['from']}\n"

    prompt += f"\nğŸ’¬ SLACK MENTIONS ({len(slack_mentions)}):\n"
    for i, mention in enumerate(slack_mentions, 1):
        prompt += f"{i}. #{mention.get('channel_name','?')}: {mention.get('text','')}\n"

    prompt += f"\nğŸ“‹ NOTION TASKS ({len(notion_tasks)}):\n"
    for i, task in enumerate(notion_tasks, 1):
        prompt += f"{i}. [{task.get('status','')}] {task.get('title','')} (Priority: {task.get('priority','')}, Due: {task.get('due_date','')})\n"

    prompt += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Create a Korean daily briefing with 4 sections:

# ğŸ“… Daily Briefing - {date_str}

## ğŸ”¥ ê¸´ê¸‰ ì²˜ë¦¬ í•­ëª© (Top 3)
(Select 3 most urgent: high priority tasks, urgent emails, code reviews, near deadlines)
1. **[Source]** Description - context
2. **[Source]** Description - context
3. **[Source]** Description - context

## â­ ì¤‘ìš” ì—…ë¬´ (Top 5)
(Select 5 important tasks/meetings/updates)
1. **Task/Meeting name** - details
2. **Task/Meeting name** - details
3. **Task/Meeting name** - details
4. **Task/Meeting name** - details
5. **Task/Meeting name** - details

## ğŸ“‹ íŒ€ ê´€ë ¨ ì—…ë°ì´íŠ¸
(Team updates from Slack and important changes)
- **#channel-name**: Update description
- **#channel-name**: Update description
- **Source**: Update description

## ğŸ’¡ ì¶”ì²œ ì•¡ì…˜ ì•„ì´í…œ
(4-5 recommended actions for today)
1. Action item
2. Action item
3. Action item
4. Action item

IMPORTANT: 
- Write ONLY in Korean
- Be concise (one line per item)
- Use **bold** for emphasis
- Start response with # ğŸ“… Daily Briefing

Generate the briefing now:"""
    return prompt

def generate_briefing(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=1500,
            temperature=0.3,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.1
        )

    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return full_text[len(prompt):].strip()

def save_markdown(content, filename):
    Path("./briefing_md").mkdir(parents=True, exist_ok=True)
    with open(f"./briefing_md/{filename}", 'w', encoding='utf-8') as f:
        f.write(content)

def main():
    # ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
    data = asyncio.run(collect_daily_briefing_data(hours=24))

    prompt = create_briefing_prompt(data)
    briefing = generate_briefing(prompt)

    timestamp = datetime.fromisoformat(data['timestamp'].split("+")[0])
    date_str = timestamp.strftime('%Yë…„ %mì›” %dì¼')
    time_str = timestamp.strftime('%Y-%m-%d %H:%M:%S')

    # ì½”ë“œ ë‚´ë¶€ í—¤ë” ë³´ì •ì—ì„œëŠ” ì´ëª¨ì§€ ì œê±°
    if not briefing.startswith("#"):
        briefing = f"# Daily Briefing - {date_str}\n\n{briefing}"

    briefing += f"\n\n---\nGenerated by AI Agent Orchestrator at {time_str} KST"

    save_markdown(briefing, "daily_briefing.md")
    print("ì™„ë£Œ! ./briefing_md/daily_briefing.md íŒŒì¼ í™•ì¸í•˜ì„¸ìš”.")  #

if __name__ == "__main__":
    main()