# Feature: Analytics Agent Implementation

## Overview
ì‚¬ìš©ì ì§ˆë¬¸ì— ê¸°ë°˜í•œ ë²„ìŠ¤ ë…¸ì„  ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì‹œìŠ¤í…œ. LangGraphë¥¼ í™œìš©í•œ intelligent routingìœ¼ë¡œ ë‘ ê°€ì§€ ì£¼ìš” ê²½ë¡œ(Find/Highlight, Analysis)ë¥¼ ì²˜ë¦¬.

## Architecture

### System Flow
```
User Question
    â†“
Intent Analysis (Router Node)
    â†“
    â”œâ”€â†’ [Find/Highlight Path]
    â”‚   â”œâ”€ get_graph_data (node_edge.json)
    â”‚   â”œâ”€ select_edge (edge selection logic)
    â”‚   â”œâ”€ Output: highlight_edge + analysis_result
    â”‚   â””â”€ Action: highlighting_edge on graph
    â”‚
    â””â”€â†’ [Analysis Path]
        â”œâ”€ get_bus_data (ìŠ¹í•˜ì°¨ì •ë³´.json + í†µê·¼ìˆ˜ë‹¹.json)
        â”œâ”€ chart_type_selector (line/bar/table/text)
        â”œâ”€ analytic (Solar Pro2 analysis)
        â”œâ”€ Output: chart_data + result
        â””â”€ output_router
            â”œâ”€ line_chart
            â”œâ”€ bar_chart
            â”œâ”€ table
            â””â”€ text_summary
```

## Data Sources

### 1. Find/Highlight Path Data
- **node_edge.json**: React Flow graph structure
  - nodes: ì •ë¥˜ì¥ ë…¸ë“œ (id, type, label, position, parentId)
  - edges: ë…¸ì„  ì—°ê²° (id, source, target, label)

### 2. Analysis Path Data
- **ìŠ¹í•˜ì°¨ì •ë³´.json** (45 records)
  ```json
  {
    "ë…¸ì„ ëª…": "ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸",
    "êµ¬ë¶„": "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼",
    "ì¶œë°œì‹œê°„": "07:00",
    "ì°¨ëŸ‰ë²ˆí˜¸": "ê²½ê¸°12ì–´1234",
    "ìˆœë²ˆ": 1,
    "ì •ë¥˜ì¥ëª…": "í•œêµ­ëŒ€ ë™ë¬¸ ë²„ìŠ¤ì •ë¥˜ì¥",
    "ìŠ¹/í•˜ì°¨": "ìŠ¹ì°¨",
    "ì¸ì›": 1
  }
  ```

- **í†µê·¼ìˆ˜ë‹¹.json** (8 records)
  ```json
  {
    "êµ¬ë¶„": "ì—…ìŠ¤í…Œì´ì§€ ì¶œê·¼",
    "ë…¸ì„ ëª…": "ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸",
    "ì¶œë°œì‹œê°„": "07:00:00",
    "ìš´í–‰ê±°ë¦¬": "10KM",
    "ìš´í–‰ë‹¨ê°€": 73000,
    "ì§€ê¸‰ìˆ˜ë‹¹": 10000,
    "ì•¼ê°„ìˆ˜ë‹¹": 15000
  }
  ```

## Implementation Plan

### Phase 1: Core LangGraph Setup

#### 1.1 State Definition (LangGraph)
```python
# backend/analytics/types/state_types.py
from typing import TypedDict, Annotated, Optional, Literal
from langgraph.graph.message import add_messages

class AnalyticsState(TypedDict):
    """
    Analytics Agentì˜ ì „ì²´ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤

    LangGraph ì‹¤í–‰ ì¤‘ ìœ ì§€ë˜ëŠ” ìƒíƒœ:
    - messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ìë™ ëˆ„ì )
    - intent_type: ì§ˆë¬¸ ìœ í˜• (find_highlight | analysis | fallback)

    Find/Highlight Path ìƒíƒœ:
    - graph_data: ReactFlow ê·¸ë˜í”„ ë°ì´í„°
    - highlight_edge: ì„ íƒëœ ì—£ì§€ ì •ë³´

    Analysis Path ìƒíƒœ:
    - transport_data: ìŠ¹í•˜ì°¨ ì •ë³´ JSON ë¬¸ìì—´
    - commute_allowance_data: í†µê·¼ ìˆ˜ë‹¹ JSON ë¬¸ìì—´
    - chart_type: ì°¨íŠ¸ íƒ€ì…
    - chart_data: ì°¨íŠ¸ ë°ì´í„°
    - analysis_result: ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
    """
    messages: Annotated[list, add_messages]
    intent_type: Optional[Literal['find_highlight', 'analysis', 'fallback']]

    # Find/Highlight specific
    graph_data: Optional[dict]
    highlight_edge: Optional[dict]

    # Analysis specific
    transport_data: Optional[str]
    commute_allowance_data: Optional[str]
    chart_type: Optional[Literal['line_chart', 'bar_chart', 'table', 'text_summary']]
    chart_data: Optional[dict]
    analysis_result: Optional[str]
```

#### 1.2 Router Node (LLM-based Intent Analysis)
```python
# backend/analytics/nodes/router.py
from analytics.types.state_types import AnalyticsState
from config import build_chat_model
from langchain_core.messages import SystemMessage
import json

def intent_analyzer(state: AnalyticsState):
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì˜ Intent ë¶„ì„ (LangGraph Node)

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ

    Returns:
        dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ {"intent_type": "find_highlight" | "analysis" | "fallback"}

    Intent Types:
    - find_highlight: íŠ¹ì • ë…¸ì„ /ì •ë¥˜ì¥ì„ ì°¾ê±°ë‚˜ í•˜ì´ë¼ì´íŠ¸í•˜ëŠ” ì§ˆë¬¸
    - analysis: ë°ì´í„° ë¶„ì„, ì°¨íŠ¸ ìƒì„±, í†µê³„ ìš”ì²­
    - fallback: ìœ„ ë‘ ê°€ì§€ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì§ˆë¬¸

    Examples:
    - "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?" â†’ find_highlight
    - "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜" â†’ analysis
    - "ì•ˆë…•í•˜ì„¸ìš”" â†’ fallback
    """
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_message = state["messages"][-1]
    user_question = user_message.content if hasattr(user_message, 'content') else str(user_message)

    # LLMì„ ì‚¬ìš©í•œ Intent ë¶„ë¥˜
    system_prompt = """
ë‹¹ì‹ ì€ ë²„ìŠ¤ ë…¸ì„  ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ Intent Classifierì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 3ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

1. **find_highlight**: íŠ¹ì • ë…¸ì„ ì´ë‚˜ ì •ë¥˜ì¥ì„ ì°¾ê±°ë‚˜ í•˜ì´ë¼ì´íŠ¸í•˜ëŠ” ì§ˆë¬¸
   - ì˜ˆì‹œ: "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?", "ìš´í–‰ ë‹¨ê°€ê°€ ê°€ì¥ ë†’ì€ ë…¸ì„ ì€?", "BYC ì‚¬ê±°ë¦¬ëŠ” ì–´ë””ì•¼?"
   - íŠ¹ì§•: "ì–´ë””", "ì–´ëŠ", "ê°€ì¥", "ìµœëŒ€", "ìµœì†Œ", "ë†’ì€", "ë‚®ì€" ë“±ì˜ í‘œí˜„ í¬í•¨
   - ëª©ì : ê·¸ë˜í”„ì—ì„œ íŠ¹ì • edge/nodeë¥¼ í•˜ì´ë¼ì´íŠ¸

2. **analysis**: ë°ì´í„° ë¶„ì„, ì°¨íŠ¸ ìƒì„±, í†µê³„ ì •ë³´ ìš”ì²­
   - ì˜ˆì‹œ: "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜", "ë…¸ì„ ë³„ ìˆ˜ìµë¥  ë¹„êµ", "ì „ì²´ ë…¸ì„  í†µê³„"
   - íŠ¹ì§•: "ë¶„ì„", "ì¶”ì´", "ë¹„êµ", "ê·¸ë˜í”„", "ì°¨íŠ¸", "í†µê³„", "í˜„í™©" ë“±ì˜ í‘œí˜„ í¬í•¨
   - ëª©ì : ì°¨íŠ¸ë‚˜ í‘œë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„° ì‹œê°í™”

3. **fallback**: ìœ„ ë‘ ê°€ì§€ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ì§ˆë¬¸
   - ì˜ˆì‹œ: "ì•ˆë…•í•˜ì„¸ìš”", "ë„ì›€ë§", "ë¬´ì—‡ì„ í•  ìˆ˜ ìˆë‚˜ìš”?"
   - ëª©ì : ê¸°ë³¸ ì‘ë‹µ ì œê³µ

ì‘ë‹µ í˜•ì‹ (JSONë§Œ ì¶œë ¥, ë‹¤ë¥¸ ì„¤ëª… ê¸ˆì§€):
{
    "intent": "find_highlight" | "analysis" | "fallback",
    "confidence": 0.0-1.0,
    "reason": "ë¶„ë¥˜ ê·¼ê±° ê°„ë‹¨íˆ ì„¤ëª…"
}
"""

    messages = [
        SystemMessage(content=system_prompt),
        user_message
    ]

    # LLM í˜¸ì¶œ
    llm = build_chat_model(temperature=0.3)
    response = llm.invoke(messages)

    try:
        # JSON íŒŒì‹±
        result = json.loads(response.content.strip())
        intent = result.get("intent", "fallback")
        confidence = result.get("confidence", 0.0)
        reason = result.get("reason", "")

        print(f"ğŸ¯ Intent Analysis (LLM): {intent} (confidence: {confidence:.2f})")
        print(f"   Reason: {reason}")

    except json.JSONDecodeError:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ fallback
        print(f"âš ï¸  Intent parsing failed, using fallback")
        intent = "fallback"

    return {"intent_type": intent}


def conditional_router(state: AnalyticsState) -> str:
    """
    Intentì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì • (LangGraph Conditional Edge)

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ

    Returns:
        str: ë‹¤ìŒ ë…¸ë“œ ì´ë¦„
    """
    intent = state.get("intent_type", "fallback")

    route_map = {
        "find_highlight": "get_graph_data",
        "analysis": "get_bus_data",
        "fallback": "fallback_response"
    }

    next_node = route_map.get(intent, "fallback_response")
    print(f"ğŸ”€ Routing to: {next_node}")

    return next_node
```

### Phase 2: Find/Highlight Path

#### 2.1 Get Graph Data Node
```python
# backend/src/analytics/nodes/find_highlight.py
def get_graph_data(state: AnalyticsState):
    """
    ReactFlow ê·¸ë˜í”„ ë°ì´í„° ë¡œë“œ
    - data/reactflow_graph_route_stop.json ì½ê¸°
    - LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ êµ¬ì¡°ë¡œ ë³€í™˜
    """
    try:
        with open("data/reactflow_graph_route_stop.json", 'r', encoding='utf-8') as f:
            raw_data = json.load(f)

        # ë…¸ë“œ ì •ë³´ ì¶”ì¶œ
        nodes = [
            {
                "id": node["id"],
                "type": node["type"],
                "label": node.get("data", {}).get("label", "")
            }
            for node in raw_data.get("nodes", [])
        ]

        # ì—£ì§€ ì •ë³´ ì¶”ì¶œ
        edges = [
            {
                "id": edge["id"],
                "source": edge["source"],
                "target": edge["target"],
                "label": edge.get("label", "")
            }
            for edge in raw_data.get("edges", [])
        ]

        summary = {
            "total_nodes": len(nodes),
            "total_edges": len(edges),
            "description": "ë²„ìŠ¤ ë…¸ì„ ê³¼ ì •ë¥˜ì¥ ì •ë³´ë¥¼ ë‹´ì€ ReactFlow ê·¸ë˜í”„"
        }

        return {
            "graph_data": {
                "nodes": nodes,
                "edges": edges,
                "summary": summary
            }
        }
    except Exception as e:
        return {"graph_data": {"error": str(e)}}
```

#### 2.2 Select Edge Node
```python
def select_edge(state: AnalyticsState):
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ì—£ì§€ ì„ íƒ

    ì˜ˆì‹œ ì§ˆë¬¸:
    - "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?"
    - "BYC ì‚¬ê±°ë¦¬ì—ì„œ ì—…ìŠ¤í…Œì´ì§€ë¡œ ê°€ëŠ” ê²½ë¡œëŠ”?"
    """
    user_question = state["messages"][-1].content
    graph_data = state.get("graph_data", {})

    edges_json = json.dumps(graph_data.get("edges", []), ensure_ascii=False)

    system_prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

    ì—£ì§€ ë°ì´í„°:
    {edges_json}

    ìœ„ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë§ëŠ” ì—£ì§€ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

    ì‘ë‹µ í˜•ì‹ (JSONë§Œ ì¶œë ¥):
    {{
        "highlight": {{
            "id": "ì—£ì§€ID",
            "source": "ì¶œë°œë…¸ë“œID",
            "target": "ë„ì°©ë…¸ë“œID",
            "label": "ì—£ì§€ë¼ë²¨"
        }},
        "reason": "ì„ íƒ ì´ìœ "
    }}
    """

    llm = build_chat_model(temperature=0.3)
    response = llm.invoke([SystemMessage(content=system_prompt)])

    result = json.loads(response.content)

    return {
        "highlight_edge": result["highlight"],
        "analysis_result": result["reason"],
        "messages": [response]
    }
```

### Phase 3: Analysis Path

#### 3.1 Get Bus Data Node
```python
# backend/src/analytics/nodes/analysis.py
def get_bus_data(state: AnalyticsState):
    """
    ë²„ìŠ¤ ë°ì´í„° ë¡œë“œ
    - ìŠ¹í•˜ì°¨ì •ë³´.json
    - í†µê·¼ìˆ˜ë‹¹.json
    """
    try:
        with open("data/ìŠ¹í•˜ì°¨ì •ë³´.json", 'r', encoding='utf-8') as f:
            transport_data = json.load(f)

        with open("data/í†µê·¼ìˆ˜ë‹¹.json", 'r', encoding='utf-8') as f:
            commute_data = json.load(f)

        return {
            "transport_data": json.dumps(transport_data, ensure_ascii=False),
            "commute_allowance_data": json.dumps(commute_data, ensure_ascii=False)
        }
    except Exception as e:
        return {
            "transport_data": "[]",
            "commute_allowance_data": "[]"
        }
```

#### 3.2 Chart Type Selector Node
```python
def chart_type_selector(state: AnalyticsState):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì— ì í•©í•œ ì°¨íŠ¸ íƒ€ì… ì„ íƒ

    Keywords:
    - line_chart: "ì¶”ì´", "ë³€í™”", "ì›”ë³„", "ì‹œê°„ë³„", "íŠ¸ë Œë“œ"
    - bar_chart: "ë¹„êµ", "ë…¸ì„ ë³„", "ìˆœìœ„", "ìƒìœ„", "í•˜ìœ„"
    - table: "ìƒì„¸", "ëª©ë¡", "ì „ì²´", "ë°ì´í„°"
    - text_summary: "ìš”ì•½", "ì„¤ëª…", "ë¶„ì„ ê²°ê³¼"
    """
    user_question = state["messages"][-1].content

    system_prompt = f"""
    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}

    ì í•©í•œ ì°¨íŠ¸ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”.
    ì„ íƒ ê°€ëŠ¥: line_chart, bar_chart, table, text_summary

    ì‘ë‹µ: ì°¨íŠ¸ íƒ€ì…ë§Œ ì˜ì–´ë¡œ ì¶œë ¥ (ì¶”ê°€ ì„¤ëª… ê¸ˆì§€)
    """

    llm = build_chat_model(temperature=0.3)
    response = llm.invoke([SystemMessage(content=system_prompt)])

    chart_type = response.content.strip()

    return {
        "chart_type": chart_type,
        "messages": state["messages"] + [response]
    }
```

#### 3.3 Generate Analytic Node
```python
def generate_analytic(state: AnalyticsState):
    """
    Solar Pro2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì„ ë° ì°¨íŠ¸ ë°ì´í„° ìƒì„±
    """
    user_question = state["messages"][0].content
    chart_type = state.get("chart_type", "text_summary")
    transport_data = state.get("transport_data", "")
    commute_data = state.get("commute_allowance_data", "")

    # ì°¨íŠ¸ë³„ output format ì •ì˜
    output_formats = {
        "line_chart": """
        {
            "chart_data": {
                "labels": ["January", "February", ...],
                "datasets": [{
                    "label": "Dataset Label",
                    "data": [65, 59, 80, ...],
                    "borderColor": "rgb(75, 192, 192)",
                    "tension": 0.1
                }]
            },
            "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
        }
        """,
        "bar_chart": """
        {
            "chart_data": {
                "labels": ["ë…¸ì„ 1", "ë…¸ì„ 2", ...],
                "datasets": [{
                    "label": "ìš´í–‰ë‹¨ê°€",
                    "data": [73000, 68000, ...],
                    "backgroundColor": "rgba(75, 192, 192, 0.6)"
                }]
            },
            "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
        }
        """,
        "table": """
        {
            "chart_data": {
                "columns": ["ë…¸ì„ ëª…", "ìš´í–‰ë‹¨ê°€", "ì§€ê¸‰ìˆ˜ë‹¹"],
                "rows": [
                    ["ì¶œê·¼1í˜¸-í•œêµ­ëŒ€ì„œë¬¸", 73000, 10000],
                    ...
                ]
            },
            "reason": "ë¶„ì„ ê²°ê³¼ ì„¤ëª…"
        }
        """,
        "text_summary": """
        {
            "chart_data": null,
            "reason": "ìƒì„¸ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸"
        }
        """
    }

    system_prompt = f"""
    êµí†µ ë°ì´í„°: {transport_data}
    í†µê·¼ ìˆ˜ë‹¹ ë°ì´í„°: {commute_data}

    ì‚¬ìš©ì ì§ˆë¬¸: {user_question}
    ì„ íƒëœ ì°¨íŠ¸: {chart_type}

    ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    ```json ê°ì‹¸ì§€ ë§ê³  ìˆœìˆ˜ JSONë§Œ ì¶œë ¥.

    Output Format:
    {output_formats[chart_type]}
    """

    llm = build_chat_model(model="solar-pro2", temperature=0.5)
    response = llm.invoke([SystemMessage(content=system_prompt)])

    result = json.loads(response.content)

    return {
        "chart_data": result["chart_data"],
        "analysis_result": result["reason"],
        "messages": state["messages"] + [response]
    }
```

### Phase 4: LangGraph Construction

```python
# backend/analytics/graph/analytics_graph.py
"""
Analytics Agent LangGraph êµ¬ì„±

Graph Flow:
    START
      â†“
    intent_analyzer
      â†“ (conditional_router)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“             â†“              â†“
get_graph_data  get_bus_data  fallback_response
    â†“             â†“              â†“
select_edge   chart_type_selector  END
    â†“             â†“
   END      generate_analytic
                  â†“
                 END
"""
from langgraph.graph import StateGraph, START, END
from analytics.types.state_types import AnalyticsState
from analytics.nodes.router import intent_analyzer, conditional_router
from analytics.nodes.find_highlight import get_graph_data, select_edge
from analytics.nodes.analysis import get_bus_data, chart_type_selector, generate_analytic
from analytics.nodes.fallback import fallback_response


def build_analytics_graph():
    """
    Analytics Agent LangGraph êµ¬ì¶•

    Returns:
        CompiledGraph: ì‹¤í–‰ ê°€ëŠ¥í•œ LangGraph ì¸ìŠ¤í„´ìŠ¤
    """
    # StateGraph ì´ˆê¸°í™”
    workflow = StateGraph(AnalyticsState)

    # ============================================================
    # Nodes ì¶”ê°€
    # ============================================================
    workflow.add_node("intent_analyzer", intent_analyzer)

    # Find/Highlight path nodes
    workflow.add_node("get_graph_data", get_graph_data)
    workflow.add_node("select_edge", select_edge)

    # Analysis path nodes
    workflow.add_node("get_bus_data", get_bus_data)
    workflow.add_node("chart_type_selector", chart_type_selector)
    workflow.add_node("generate_analytic", generate_analytic)

    # Fallback node
    workflow.add_node("fallback_response", fallback_response)

    # ============================================================
    # Edges êµ¬ì„±
    # ============================================================

    # Entry point
    workflow.set_entry_point("intent_analyzer")

    # Conditional routing (intentì— ë”°ë¼ ë¶„ê¸°)
    workflow.add_conditional_edges(
        "intent_analyzer",
        conditional_router,
        {
            "get_graph_data": "get_graph_data",
            "get_bus_data": "get_bus_data",
            "fallback_response": "fallback_response"
        }
    )

    # Find/Highlight path: get_graph_data â†’ select_edge â†’ END
    workflow.add_edge("get_graph_data", "select_edge")
    workflow.add_edge("select_edge", END)

    # Analysis path: get_bus_data â†’ chart_type_selector â†’ generate_analytic â†’ END
    workflow.add_edge("get_bus_data", "chart_type_selector")
    workflow.add_edge("chart_type_selector", "generate_analytic")
    workflow.add_edge("generate_analytic", END)

    # Fallback: fallback_response â†’ END
    workflow.add_edge("fallback_response", END)

    # ============================================================
    # Compile and return
    # ============================================================
    compiled_graph = workflow.compile()

    print("âœ… Analytics Agent LangGraph êµ¬ì¶• ì™„ë£Œ")

    return compiled_graph


# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
_analytics_graph = None

def get_analytics_graph():
    """
    Analytics Graph ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Returns:
        CompiledGraph: Analytics Agent ê·¸ë˜í”„
    """
    global _analytics_graph
    if _analytics_graph is None:
        _analytics_graph = build_analytics_graph()
    return _analytics_graph
```

#### Fallback Node ì¶”ê°€

```python
# backend/analytics/nodes/fallback.py
from analytics.types.state_types import AnalyticsState
from langchain_core.messages import AIMessage

def fallback_response(state: AnalyticsState):
    """
    Intent ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ (LangGraph Node)

    Args:
        state (AnalyticsState): í˜„ì¬ ê·¸ë˜í”„ ìƒíƒœ

    Returns:
        dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ
    """
    fallback_message = """
ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”:
- "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?" (Find/Highlight)
- "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜" (Analysis)
- "ë…¸ì„ ë³„ ìˆ˜ìµë¥  ë¹„êµí•´ì¤˜" (Analysis)
    """

    response = AIMessage(content=fallback_message.strip())

    return {
        "messages": [response],
        "analysis_result": fallback_message.strip()
    }
```

### Phase 5: Frontend Integration (Right Panel)

#### 5.1 Chat Interface Component
```typescript
// frontend/app/route-visualization/components/RightPanel.tsx
'use client';

import { useState } from 'react';
import { sendMessage } from '../utils/analytics-api';
import { AnalyticsOutputRenderer } from './AnalyticsOutputRenderer';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  chart_type?: 'line_chart' | 'bar_chart' | 'table' | 'text_summary';
  chart_data?: any;
  highlight_edge?: any;
  intent_type?: string;
}

export function RightPanel({ onHighlightEdge }: { onHighlightEdge: (edge: any) => void }) {
  const [messages, setMessages] = useState<Message[]>([]);
  const [input, setInput] = useState('');
  const [loading, setLoading] = useState(false);

  const handleSend = async () => {
    if (!input.trim()) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: input
    };
    setMessages(prev => [...prev, userMessage]);
    setInput('');
    setLoading(true);

    try {
      const response = await sendMessage(input);

      // Find/Highlight: edge highlighting
      if (response.intent_type === 'find_highlight' && response.highlight_edge) {
        onHighlightEdge(response.highlight_edge);
      }

      const assistantMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: response.analysis_result || 'ë¶„ì„ ì™„ë£Œ',
        chart_type: response.chart_type,
        chart_data: response.chart_data,
        highlight_edge: response.highlight_edge,
        intent_type: response.intent_type
      };

      setMessages(prev => [...prev, assistantMessage]);
    } catch (error) {
      console.error('Failed to send message:', error);
      setMessages(prev => [...prev, {
        id: Date.now().toString(),
        role: 'assistant',
        content: 'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      }]);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-full bg-gray-900">
      {/* Header */}
      <div className="px-6 py-4 border-b border-gray-700">
        <h2 className="text-lg font-semibold text-white">Analytics Chat</h2>
        <p className="text-sm text-gray-400 mt-1">ë²„ìŠ¤ ë…¸ì„  ë°ì´í„° ë¶„ì„ ë° ì§ˆì˜</p>
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto px-6 py-4 space-y-6">
        {messages.length === 0 ? (
          <div className="h-full flex items-center justify-center text-gray-500">
            <div className="text-center">
              <p className="text-lg mb-2">ğŸ’¬</p>
              <p>ì§ˆë¬¸ì„ ì…ë ¥í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”</p>
              <div className="mt-4 text-sm text-gray-600">
                <p>ì˜ˆì‹œ:</p>
                <ul className="mt-2 space-y-1">
                  <li>â€¢ ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?</li>
                  <li>â€¢ ì›”ë³„ ìš´í–‰ ë‹¨ê°€ ì¶”ì´ë¥¼ ë³´ì—¬ì¤˜</li>
                  <li>â€¢ ë…¸ì„ ë³„ ìˆ˜ìµë¥  ë¹„êµí•´ì¤˜</li>
                </ul>
              </div>
            </div>
          </div>
        ) : (
          messages.map((msg) => (
            <div key={msg.id}>
              {/* User message */}
              {msg.role === 'user' && (
                <div className="flex justify-end">
                  <div className="bg-blue-600 text-white rounded-lg px-4 py-2 max-w-[80%]">
                    {msg.content}
                  </div>
                </div>
              )}

              {/* Assistant message */}
              {msg.role === 'assistant' && (
                <div className="flex justify-start">
                  <div className="bg-gray-800 rounded-lg p-4 max-w-[90%] w-full">
                    {/* Find/Highlight response */}
                    {msg.intent_type === 'find_highlight' && msg.highlight_edge && (
                      <div className="mb-4 p-3 bg-green-900/30 border border-green-700 rounded">
                        <p className="text-green-200 text-sm mb-2">
                          ğŸ¯ í•˜ì´ë¼ì´íŠ¸: {msg.highlight_edge.label}
                        </p>
                        <p className="text-gray-300 text-sm">{msg.content}</p>
                      </div>
                    )}

                    {/* Analysis response */}
                    {msg.intent_type === 'analysis' && msg.chart_type && (
                      <AnalyticsOutputRenderer
                        chartType={msg.chart_type}
                        chartData={msg.chart_data}
                        analysisResult={msg.content}
                        renderHint={{
                          insights: [], // LLMì—ì„œ ì¶”ì¶œ ê°€ëŠ¥
                          chart_config: {} // ì°¨íŠ¸ ì„¤ì •
                        }}
                      />
                    )}

                    {/* Fallback text */}
                    {!msg.chart_type && !msg.highlight_edge && (
                      <p className="text-gray-200">{msg.content}</p>
                    )}
                  </div>
                </div>
              )}
            </div>
          ))
        )}

        {loading && (
          <div className="flex justify-start">
            <div className="bg-gray-800 rounded-lg px-4 py-2">
              <div className="flex space-x-2">
                <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce" />
                <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce delay-100" />
                <div className="w-2 h-2 bg-gray-500 rounded-full animate-bounce delay-200" />
              </div>
            </div>
          </div>
        )}
      </div>

      {/* Input */}
      <div className="px-6 py-4 border-t border-gray-700">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && !loading && handleSend()}
            placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."
            disabled={loading}
            className="flex-1 bg-gray-800 text-white rounded-lg px-4 py-3 outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50"
          />
          <button
            onClick={handleSend}
            disabled={loading || !input.trim()}
            className="bg-blue-600 hover:bg-blue-700 disabled:bg-gray-700 text-white rounded-lg px-6 py-3 font-medium transition-colors"
          >
            ì „ì†¡
          </button>
        </div>
      </div>
    </div>
  );
}
```

#### 5.2 Output Renderer Integration

ê¸°ì¡´ chart renderer í™œìš©:
- `TextWithLineChartRenderer.tsx`: Line chart + insights
- `TextWithBarChartRenderer.tsx`: Bar chart + ranking analysis
- `TextWithTableRenderer.tsx`: Data table + statistics
- `DetailTextRenderer.tsx`: Text summary + key points

```typescript
// frontend/app/route-visualization/components/AnalyticsOutputRenderer.tsx
'use client';

import { TextWithLineChartRenderer } from '../chart_renderers/TextWithLineChartRenderer';
import { TextWithBarChartRenderer } from '../chart_renderers/TextWithBarChartRenderer';
import { TextWithTableRenderer } from '../chart_renderers/TextWithTableRenderer';
import { DetailTextRenderer } from '../chart_renderers/DetailTextRenderer';

interface AnalyticsOutputRendererProps {
  chartType: 'line_chart' | 'bar_chart' | 'table' | 'text_summary';
  chartData: any;
  analysisResult: string;
  renderHint?: Record<string, any>;
}

export function AnalyticsOutputRenderer({
  chartType,
  chartData,
  analysisResult,
  renderHint
}: AnalyticsOutputRendererProps) {
  // Message í¬ë§· ë³€í™˜ (ê¸°ì¡´ renderer ì¸í„°í˜ì´ìŠ¤ ì¤€ìˆ˜)
  const message = {
    id: Date.now().toString(),
    role: 'assistant' as const,
    content: analysisResult,
    chart_data: chartData,
    chart_config: renderHint?.chart_config,
    timestamp: new Date()
  };

  switch (chartType) {
    case 'line_chart':
      return <TextWithLineChartRenderer message={message} renderHint={renderHint} />;

    case 'bar_chart':
      return <TextWithBarChartRenderer message={message} renderHint={renderHint} />;

    case 'table':
      return <TextWithTableRenderer message={message} renderHint={renderHint} />;

    case 'text_summary':
    default:
      return <DetailTextRenderer message={message} renderHint={renderHint} />;
  }
}
```

#### 5.3 API Client
```typescript
// frontend/app/route-visualization/utils/analytics-api.ts
export async function sendMessage(question: string) {
  const response = await fetch('/api/analytics', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ question })
  });

  if (!response.ok) {
    throw new Error('Failed to analyze');
  }

  return response.json();
}
```

#### 5.4 Backend FastAPI Setup

```python
# backend/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from api.routes import analytics

app = FastAPI(
    title="Smartway Analytics API",
    description="ë²„ìŠ¤ ë…¸ì„  ë¶„ì„ ë° ì‹œê°í™” API",
    version="1.0.0"
)

# CORS ì„¤ì • (Next.jsì™€ í†µì‹ )
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Next.js dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routes ë“±ë¡
app.include_router(analytics.router, prefix="/api", tags=["analytics"])

@app.get("/")
async def root():
    return {"message": "Smartway Analytics API"}

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
```

```python
# backend/config.py
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

load_dotenv()

UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def build_chat_model(model: str = "solar-pro", temperature: float = 0.7):
    """LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    if model == "solar-pro2":
        return ChatOpenAI(
            model="solar-pro2",
            api_key=UPSTAGE_API_KEY,
            base_url="https://api.upstage.ai/v1/solar",
            temperature=temperature
        )
    return ChatOpenAI(
        model="solar-pro",
        api_key=UPSTAGE_API_KEY,
        base_url="https://api.upstage.ai/v1/solar",
        temperature=temperature
    )
```

```python
# backend/api/routes/analytics.py
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional, Dict, Any
from langchain_core.messages import HumanMessage
from analytics.graph.analytics_graph import get_analytics_graph

router = APIRouter()

class QuestionRequest(BaseModel):
    question: str

class AnalyticsResponse(BaseModel):
    intent_type: str
    highlight_edge: Optional[Dict[str, Any]] = None
    chart_data: Optional[Dict[str, Any]] = None
    analysis_result: Optional[str] = None
    chart_type: Optional[str] = None

@router.post("/analytics", response_model=AnalyticsResponse)
async def analyze(request: QuestionRequest):
    """
    Analytics Agent API - LangGraph ì‹¤í–‰

    Flow:
    1. ì‚¬ìš©ì ì§ˆë¬¸ì„ HumanMessageë¡œ ë³€í™˜
    2. LangGraph invokeë¡œ ì‹¤í–‰
    3. ê²°ê³¼ stateì—ì„œ ì‘ë‹µ ì¶”ì¶œ
    4. FastAPI response modelë¡œ ë°˜í™˜

    Example:
        POST /api/analytics
        Body: {"question": "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?"}
        Response: {
            "intent_type": "find_highlight",
            "highlight_edge": {...},
            "analysis_result": "..."
        }
    """
    try:
        # LangGraph ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        analytics_graph = get_analytics_graph()

        # Initial state êµ¬ì„± (LangGraph í˜•ì‹)
        initial_state = {
            "messages": [HumanMessage(content=request.question)]
        }

        # LangGraph ì‹¤í–‰
        print(f"ğŸ“¨ Received question: {request.question}")
        result = analytics_graph.invoke(initial_state)
        print(f"âœ… LangGraph execution completed")

        # Stateì—ì„œ ê²°ê³¼ ì¶”ì¶œ
        response_data = AnalyticsResponse(
            intent_type=result.get("intent_type", "fallback"),
            highlight_edge=result.get("highlight_edge"),
            chart_data=result.get("chart_data"),
            analysis_result=result.get("analysis_result"),
            chart_type=result.get("chart_type")
        )

        return response_data

    except Exception as e:
        print(f"âŒ Error in analytics: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/health")
async def health():
    """Health check endpoint"""
    return {"status": "analytics service healthy"}
```

### Phase 6: Edge Highlighting Integration

```typescript
// frontend/app/route-visualization/ocel-demo/route-flow.tsx
export function RouteFlow({ highlightedEdge }: { highlightedEdge?: any }) {
  const [edges, setEdges] = useState<Edge[]>(initialEdges);

  useEffect(() => {
    if (highlightedEdge) {
      setEdges(edges =>
        edges.map(edge => ({
          ...edge,
          animated: edge.id === highlightedEdge.id,
          style: {
            ...edge.style,
            stroke: edge.id === highlightedEdge.id ? '#ef4444' : '#94a3b8',
            strokeWidth: edge.id === highlightedEdge.id ? 3 : 2
          }
        }))
      );
    }
  }, [highlightedEdge]);

  return <ReactFlow nodes={nodes} edges={edges} />;
}
```

## Example Queries & Expected Responses

### Find/Highlight Examples

| ì§ˆë¬¸ | Intent | Output |
|-----|--------|--------|
| "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?" | find_highlight | ìŠ¹ì°¨ ì¸ì›ì´ ê°€ì¥ ë§ì€ edge í•˜ì´ë¼ì´íŒ… |
| "BYC ì‚¬ê±°ë¦¬ì—ì„œ ì—…ìŠ¤í…Œì´ì§€ë¡œ ê°€ëŠ” ê²½ë¡œëŠ”?" | find_highlight | í•´ë‹¹ ë…¸ë“œ ê°„ edge í•˜ì´ë¼ì´íŒ… |
| "ìš´í–‰ ë‹¨ê°€ê°€ ê°€ì¥ ë†’ì€ ë…¸ì„ ì€?" | find_highlight | í†µê·¼ìˆ˜ë‹¹ ë°ì´í„° ê¸°ë°˜ edge í•˜ì´ë¼ì´íŒ… |

### Analysis Examples

| ì§ˆë¬¸ | Chart Type | Output |
|-----|-----------|--------|
| "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ í˜„í™© ì•Œë ¤ì¤˜" | line_chart | ì‹œê³„ì—´ ë¼ì¸ ì°¨íŠ¸ |
| "ë…¸ì„ ë³„ ìˆ˜ìµë¥  ë¹„êµí•´ì¤˜" | bar_chart | ë…¸ì„ ë³„ ë°” ì°¨íŠ¸ |
| "ì§€ê¸‰ ìˆ˜ë‹¹ì´ ê°€ì¥ ë†’ì€ ë…¸ì„ ì€?" | table | ì •ë ¬ëœ í…Œì´ë¸” |
| "ì•¼ê°„ ìˆ˜ë‹¹ ë¶„ì„ ê²°ê³¼ ìš”ì•½í•´ì¤˜" | text_summary | í…ìŠ¤íŠ¸ ìš”ì•½ |

## File Structure

```
smartway-dev/
â”œâ”€â”€ backend/                    # FastAPI Backend
â”‚   â”œâ”€â”€ main.py                # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py              # Configuration (API keys, settings)
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ state_types.py
â”‚   â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py
â”‚   â”‚   â”‚   â”œâ”€â”€ find_highlight.py
â”‚   â”‚   â”‚   â””â”€â”€ analysis.py
â”‚   â”‚   â””â”€â”€ graph/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ analytics_graph.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ routes/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ analytics.py
â”‚
â”œâ”€â”€ data/                      # Shared data directory
â”‚   â”œâ”€â”€ reactflow_graph_route_stop.json
â”‚   â”œâ”€â”€ ìŠ¹í•˜ì°¨ì •ë³´.json
â”‚   â””â”€â”€ í†µê·¼ìˆ˜ë‹¹.json
â”‚
â””â”€â”€ frontend/                  # Next.js Frontend
    â””â”€â”€ app/
        â””â”€â”€ route-visualization/
            â”œâ”€â”€ page.tsx (updated with RightPanel)
            â”œâ”€â”€ components/
            â”‚   â”œâ”€â”€ RightPanel.tsx
            â”‚   â”œâ”€â”€ ChatMessage.tsx
            â”‚   â”œâ”€â”€ ChartRenderer.tsx
            â”‚   â””â”€â”€ ... (existing components)
            â””â”€â”€ utils/
                â””â”€â”€ analytics-api.ts
```

## Dependencies

### Backend (FastAPI)
```txt
# requirements.txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.0
pydantic-settings==2.1.0
python-dotenv==1.0.0

langgraph==0.2.0
langchain-openai==0.1.0
langchain-core==0.1.0

python-multipart==0.0.6
```

### Frontend
ê¸°ì¡´ chart rendererê°€ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì¶”ê°€ ì„¤ì¹˜ ë¶ˆí•„ìš”.

í™•ì¸ í•„ìš”í•œ ì˜ì¡´ì„±:
```bash
# ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•¨
# - @/lib/types (Message íƒ€ì…)
# - @/components/charts/ChartRenderer
# - @/components/charts/DataTable
# - @/components/ui/button
```

### Environment Setup
```bash
# backend/.env
UPSTAGE_API_KEY=your_api_key_here
OPENAI_API_KEY=your_api_key_here  # if needed
ENVIRONMENT=development
```

## Testing Strategy

### Unit Tests
- `router.py`: Intent classification accuracy
- `find_highlight.py`: Edge selection logic
- `analysis.py`: Chart type selection logic

### Integration Tests
- Full graph execution with sample questions
- API endpoint response validation
- Frontend-backend communication

### Example Test Cases
```python
# test_router.py
def test_find_highlight_intent():
    state = {"messages": [{"content": "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?"}]}
    result = intent_analyzer(state)
    assert result["intent_type"] == "find_highlight"

def test_analysis_intent():
    state = {"messages": [{"content": "ì›”ë³„ ìš´í–‰ ë‹¨ê°€ í˜„í™©"}]}
    result = intent_analyzer(state)
    assert result["intent_type"] == "analysis"
```

## Success Metrics

1. **Accuracy**: Intent classification â‰¥90%
2. **Response Time**: < 3 seconds for analysis
3. **Chart Quality**: Correct chart type selection â‰¥85%
4. **Highlight Accuracy**: Correct edge selection â‰¥90%
5. **User Experience**: Smooth chat interface, no lag

## Timeline Estimate

- Phase 1 (State & Router): 2-3 hours
- Phase 2 (Find/Highlight): 3-4 hours
- Phase 3 (Analysis): 4-5 hours
- Phase 4 (Graph): 1-2 hours
- Phase 5 (Frontend): 4-5 hours
- Phase 6 (Integration): 2-3 hours
- Testing: 2-3 hours

**Total**: 18-25 hours for full implementation

## Quick Start Guide

### Backend Setup
```bash
# 1. Create backend directory
mkdir backend && cd backend

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file
echo "UPSTAGE_API_KEY=your_key_here" > .env

# 5. Run FastAPI server
python main.py
# Server running at http://localhost:8000
# Docs at http://localhost:8000/docs
```

### Frontend Setup
```bash
# 1. Navigate to frontend
cd frontend

# 2. Install dependencies
npm install react-chartjs-2 chart.js

# 3. Update Next.js config (if needed)
# Add proxy to backend in next.config.js

# 4. Run dev server
npm run dev
# Server running at http://localhost:3000
```

### Testing the API
```bash
# Test health endpoint
curl http://localhost:8000/health

# Test analytics endpoint
curl -X POST http://localhost:8000/api/analytics \
  -H "Content-Type: application/json" \
  -d '{"question": "ê°€ì¥ í¬í™”ê°€ ë§ì€ ë…¸ì„ ì€?"}'
```

## Next Steps

1. âœ… Create specification document
2. â¬œ Setup FastAPI backend structure
3. â¬œ Implement LangGraph nodes
4. â¬œ Create FastAPI routes
5. â¬œ Develop frontend RightPanel
6. â¬œ Integrate with RouteFlow
7. â¬œ Test with real data
8. â¬œ Deploy and monitor
