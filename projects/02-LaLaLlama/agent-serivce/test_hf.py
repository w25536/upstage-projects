# test_hf.py

import os
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEndpoint

# 1. .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
load_dotenv()

print("--- Hugging Face API ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")

# 2. .env íŒŒì¼ì—ì„œ HUGGINGFACEHUB_API_TOKENì„ ì œëŒ€ë¡œ ì½ì–´ì˜¤ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
api_token = os.getenv("HUGGINGFACEHUB_API_TOKEN")

if api_token:
    # í† í°ì˜ ì¼ë¶€ë§Œ ì¶œë ¥í•˜ì—¬ ë¡œë”© ì—¬ë¶€ í™•ì¸ (ë³´ì•ˆì„ ìœ„í•´ ì „ì²´ í† í°ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŒ)
    print(f"âœ… API Token ë¡œë“œ ì„±ê³µ: '{api_token[:5]}...'")
else:
    print("âŒ API Token ë¡œë“œ ì‹¤íŒ¨! .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    # í† í°ì´ ì—†ìœ¼ë©´ í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
    exit()

try:
    # 3. LLM ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    print("\nLLM ê°ì²´ ìƒì„± ì‹œë„...")
    llm = HuggingFaceEndpoint(
        repo_id="mistralai/Mistral-7B-Instruct-v0.2",
        huggingfacehub_api_token=api_token,
        temperature=0.1,
        max_new_tokens=1024
    )
    print("âœ… LLM ê°ì²´ ìƒì„± ì„±ê³µ!")

    # 4. LLMì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ë°›ì•„ì˜µë‹ˆë‹¤.
    print("\nLLM í˜¸ì¶œ ì‹œë„...")
    response = llm.invoke("Hi, how are you today?")
    print("âœ… LLM í˜¸ì¶œ ì„±ê³µ!")
    print("\n--- LLM ì‘ë‹µ ---")
    print(response)
    print("\n--------------------")
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ! API í‚¤ì™€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")

except Exception as e:
    print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
    print("--- ë°œìƒí•œ ì—ëŸ¬ ---")
    print(e)
    print("\n--------------------")