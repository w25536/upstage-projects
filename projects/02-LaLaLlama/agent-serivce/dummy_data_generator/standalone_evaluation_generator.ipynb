{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë…ë¦½í˜• ì œì•ˆì„œ í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±ê¸°\n",
    "\n",
    "## íŠ¹ì§•\n",
    "- âœ… **RFP íŒŒì¼ ë¶ˆí•„ìš”**: GPTê°€ ì§ì ‘ RFP ìš”êµ¬ì‚¬í•­ê³¼ ì œì•ˆì„œ ë‚´ìš©ì„ ìƒì„±\n",
    "- âœ… **ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥**: API í‚¤ë§Œ ì…ë ¥í•˜ë©´ ë°”ë¡œ ë°ì´í„°ì…‹ ìƒì„±\n",
    "- âœ… **JSONL í˜•ì‹**: Fine-tuningì— ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•ì‹\n",
    "\n",
    "## ì¶œë ¥ í˜•ì‹\n",
    "```jsonl\n",
    "{\"instruction\": \"ì‹¬ì‚¬ ê¸°ì¤€í‘œì— ë§ì¶° í‰ê°€ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\", \"input\": \"...\", \"output\": \"[ì ìˆ˜] X/Y\\n[ì½”ë©˜íŠ¸] ...\"}\n",
    "```\n",
    "\n",
    "## ë°ì´í„°ì…‹ êµ¬ì„± ì „ëµ\n",
    "\n",
    "### 1. IT ë„ë©”ì¸ë³„ ë¶„ë¥˜ (20%ì”©)\n",
    "- IT ì‹œìŠ¤í…œ êµ¬ì¶•: ERP, í˜‘ì—… í”Œë«í¼, MSA ì „í™˜\n",
    "- ë°ì´í„°/AI: ë¹…ë°ì´í„°, ML íŒŒì´í”„ë¼ì¸, AI ë¶„ì„\n",
    "- ëª¨ë°”ì¼/ì›¹: ì•± ê°œë°œ, PWA, ë°˜ì‘í˜• ì›¹\n",
    "- ì¸í”„ë¼/ë³´ì•ˆ: í´ë¼ìš°ë“œ, DevOps, ë³´ì•ˆ ê´€ì œ\n",
    "- IoT/ìŠ¤ë§ˆíŠ¸ì‹œìŠ¤í…œ: IoT í”Œë«í¼, ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬\n",
    "\n",
    "### 2. í‰ê°€ ìœ í˜• (instruction-input-output)\n",
    "- **ì „ì²´ í‰ê°€** (20%): 100ì  ë§Œì \n",
    "- **í•­ëª©ë³„ í‰ê°€** (50%): ê¸°ìˆ ì—­ëŸ‰(30ì ), ê°€ê²©(25ì ), ê²½í—˜(20ì ), ì „ëµ(15ì ), ì•ˆì •ì„±(10ì )\n",
    "- **ì„¸ë¶€ ì„¹ì…˜** (30%): 10ì  ë§Œì  (ì•ˆì •í™”, ì¥ì• ëŒ€ì‘, ëª¨ë‹ˆí„°ë§, ë¦¬ìŠ¤í¬, ì•„í‚¤í…ì²˜)\n",
    "\n",
    "### 3. ì ìˆ˜ ë¶„í¬ (í˜„ì‹¤ì )\n",
    "- 90-100%: 15% (ì™„ë²½)\n",
    "- 80-89%: 25% (ìš°ìˆ˜)\n",
    "- 70-79%: 30% (ì–‘í˜¸)\n",
    "- 50-69%: 20% (ë³´í†µ)\n",
    "- 30-49%: 10% (ë¯¸í¡)\n",
    "\n",
    "### 4. ê¶Œì¥ ê·œëª¨\n",
    "- í…ŒìŠ¤íŠ¸: 100ê°œ (1-2ë¶„)\n",
    "- ìµœì†Œ: 1,000ê°œ (10-15ë¶„)\n",
    "- **ê¶Œì¥: 5,000ê°œ (50-70ë¶„)** â­\n",
    "- ì´ìƒì : 10,000ê°œ (100-140ë¶„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport random\nfrom datetime import datetime\nfrom openai import OpenAI\nfrom tqdm import tqdm\n\n# OpenAI API í‚¤ ì„¤ì •\nOPENAI_API_KEY = \"YOUR_OPENAI_API_KEY_HERE\"  # ì—¬ê¸°ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš” (sk-proj-... í˜•ì‹)\nclient = OpenAI(api_key=OPENAI_API_KEY)\n\n# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\nOUTPUT_DIR = \"evaluation_training_data\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")\nprint(f\"ì¶œë ¥ ë””ë ‰í† ë¦¬: {OUTPUT_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„° ìƒì„± ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IT í”„ë¡œì íŠ¸ ë„ë©”ì¸ (5ê°œ ë¶„ì•¼)\n",
    "IT_DOMAINS = [\n",
    "    \"IT_ì‹œìŠ¤í…œêµ¬ì¶•\",\n",
    "    \"ë°ì´í„°_AI\",\n",
    "    \"ëª¨ë°”ì¼_ì›¹\",\n",
    "    \"ì¸í”„ë¼_ë³´ì•ˆ\",\n",
    "    \"IoT_ìŠ¤ë§ˆíŠ¸ì‹œìŠ¤í…œ\"\n",
    "]\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ìœ í˜• (ë„ë©”ì¸ë³„)\n",
    "PROJECT_TYPES = {\n",
    "    \"IT_ì‹œìŠ¤í…œêµ¬ì¶•\": [\n",
    "        \"ì „ì‚¬ ERP ì‹œìŠ¤í…œ êµ¬ì¶•\",\n",
    "        \"í´ë¼ìš°ë“œ ê¸°ë°˜ í˜‘ì—… í”Œë«í¼\",\n",
    "        \"ë ˆê±°ì‹œ ì‹œìŠ¤í…œ í˜„ëŒ€í™”\",\n",
    "        \"ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì „í™˜\",\n",
    "        \"í†µí•© ì¸ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•\"\n",
    "    ],\n",
    "    \"ë°ì´í„°_AI\": [\n",
    "        \"AI ê¸°ë°˜ ê³ ê° ë¶„ì„ í”Œë«í¼\",\n",
    "        \"ë¹…ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\",\n",
    "        \"ML ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸ë§ ì‹œìŠ¤í…œ\",\n",
    "        \"ì‹¤ì‹œê°„ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ\",\n",
    "        \"ì¶”ì²œ ì—”ì§„ ê°œë°œ\"\n",
    "    ],\n",
    "    \"ëª¨ë°”ì¼_ì›¹\": [\n",
    "        \"í¬ë¡œìŠ¤ í”Œë«í¼ ëª¨ë°”ì¼ ì•±\",\n",
    "        \"ë°˜ì‘í˜• ì›¹ í¬í„¸ êµ¬ì¶•\",\n",
    "        \"PWA ê¸°ë°˜ ì„œë¹„ìŠ¤\",\n",
    "        \"í•˜ì´ë¸Œë¦¬ë“œ ì•± ê°œë°œ\",\n",
    "        \"ì›¹ ì ‘ê·¼ì„± ê°œì„  í”„ë¡œì íŠ¸\"\n",
    "    ],\n",
    "    \"ì¸í”„ë¼_ë³´ì•ˆ\": [\n",
    "        \"í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜\",\n",
    "        \"DevOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\",\n",
    "        \"í†µí•© ë³´ì•ˆ ê´€ì œ ì‹œìŠ¤í…œ\",\n",
    "        \"ì œë¡œíŠ¸ëŸ¬ìŠ¤íŠ¸ ë³´ì•ˆ ì•„í‚¤í…ì²˜\",\n",
    "        \"DR/BCP ì‹œìŠ¤í…œ êµ¬ì¶•\"\n",
    "    ],\n",
    "    \"IoT_ìŠ¤ë§ˆíŠ¸ì‹œìŠ¤í…œ\": [\n",
    "        \"IoT ì„¼ì„œ í†µí•© í”Œë«í¼\",\n",
    "        \"ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì‹œìŠ¤í…œ\",\n",
    "        \"ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì†”ë£¨ì…˜\",\n",
    "        \"ë””ì§€í„¸ íŠ¸ìœˆ êµ¬ì¶•\",\n",
    "        \"ì—£ì§€ ì»´í“¨íŒ… í”Œë«í¼\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# í‰ê°€ ìœ í˜• ë° ë§Œì \n",
    "EVALUATION_TYPES = {\n",
    "    \"ì „ì²´_í‰ê°€\": {\n",
    "        \"ë§Œì \": 100,\n",
    "        \"ë¹„ìœ¨\": 0.20,\n",
    "        \"ì„¤ëª…\": \"RFP ì „ì²´ ëŒ€ë¹„ ì œì•ˆì„œ ì „ì²´ í‰ê°€\"\n",
    "    },\n",
    "    \"ê¸°ìˆ ì—­ëŸ‰\": {\n",
    "        \"ë§Œì \": 30,\n",
    "        \"ë¹„ìœ¨\": 0.15,\n",
    "        \"ì„¤ëª…\": \"ê¸°ìˆ  ì•„í‚¤í…ì²˜, ê¸°ìˆ  ìŠ¤íƒ, ì„±ëŠ¥ ë°©ì•ˆ\"\n",
    "    },\n",
    "    \"ê°€ê²©ê²½ìŸë ¥\": {\n",
    "        \"ë§Œì \": 25,\n",
    "        \"ë¹„ìœ¨\": 0.10,\n",
    "        \"ì„¤ëª…\": \"ì‚¬ì—…ë¹„ ì ì •ì„±, ë¹„ìš© ì‚°ì • í•©ë¦¬ì„±\"\n",
    "    },\n",
    "    \"ìˆ˜í–‰ê²½í—˜\": {\n",
    "        \"ë§Œì \": 20,\n",
    "        \"ë¹„ìœ¨\": 0.10,\n",
    "        \"ì„¤ëª…\": \"ìœ ì‚¬ í”„ë¡œì íŠ¸ ì‹¤ì , ì„±ê³µ ì‚¬ë¡€\"\n",
    "    },\n",
    "    \"ì¶”ì§„ì „ëµ\": {\n",
    "        \"ë§Œì \": 15,\n",
    "        \"ë¹„ìœ¨\": 0.10,\n",
    "        \"ì„¤ëª…\": \"í”„ë¡œì íŠ¸ ê´€ë¦¬, ì¼ì • ê³„íš\"\n",
    "    },\n",
    "    \"ì•ˆì •ì„±_ë¦¬ìŠ¤í¬ê´€ë¦¬\": {\n",
    "        \"ë§Œì \": 10,\n",
    "        \"ë¹„ìœ¨\": 0.05,\n",
    "        \"ì„¤ëª…\": \"ì•ˆì •í™”, ëª¨ë‹ˆí„°ë§, ë¦¬ìŠ¤í¬ ê´€ë¦¬\"\n",
    "    },\n",
    "    \"ì„œë¹„ìŠ¤_ì•ˆì •í™”\": {\n",
    "        \"ë§Œì \": 10,\n",
    "        \"ë¹„ìœ¨\": 0.075,\n",
    "        \"ì„¤ëª…\": \"ì„±ëŠ¥ ëª©í‘œ, ë¶€í•˜ í…ŒìŠ¤íŠ¸, íŠœë‹ ì „ëµ\"\n",
    "    },\n",
    "    \"ì¥ì• _ëŒ€ì‘_ë³µêµ¬\": {\n",
    "        \"ë§Œì \": 10,\n",
    "        \"ë¹„ìœ¨\": 0.075,\n",
    "        \"ì„¤ëª…\": \"ì¥ì•  ë“±ê¸‰, RTO/RPO, ë³µêµ¬ ì „ëµ\"\n",
    "    },\n",
    "    \"ëª¨ë‹ˆí„°ë§_ê´€ì°°ì„±\": {\n",
    "        \"ë§Œì \": 10,\n",
    "        \"ë¹„ìœ¨\": 0.075,\n",
    "        \"ì„¤ëª…\": \"ëª¨ë‹ˆí„°ë§ ë„êµ¬, ì§€í‘œ ìˆ˜ì§‘, ëŒ€ì‹œë³´ë“œ\"\n",
    "    },\n",
    "    \"ë¦¬ìŠ¤í¬_ê´€ë¦¬\": {\n",
    "        \"ë§Œì \": 10,\n",
    "        \"ë¹„ìœ¨\": 0.075,\n",
    "        \"ì„¤ëª…\": \"ë¦¬ìŠ¤í¬ ì‹ë³„, ì™„í™” ì „ëµ, ë¹„ìƒ ê³„íš\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ìƒì„± ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"  - IT ë„ë©”ì¸: {len(IT_DOMAINS)}ê°œ\")\n",
    "print(f\"  - í‰ê°€ ìœ í˜•: {len(EVALUATION_TYPES)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í‰ê°€ ìƒ˜í”Œ ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_score_by_distribution():\n    \"\"\"\n    í˜„ì‹¤ì ì¸ ì ìˆ˜ ë¶„í¬ì— ë”°ë¼ ì ìˆ˜ ë¹„ìœ¨ ë°˜í™˜ (0.0-1.0)\n    \"\"\"\n    rand = random.random()\n    if rand < 0.15:\n        return random.uniform(0.90, 1.00)  # 90-100%: 15%\n    elif rand < 0.40:\n        return random.uniform(0.80, 0.89)  # 80-89%: 25%\n    elif rand < 0.70:\n        return random.uniform(0.70, 0.79)  # 70-79%: 30%\n    elif rand < 0.90:\n        return random.uniform(0.50, 0.69)  # 50-69%: 20%\n    else:\n        return random.uniform(0.30, 0.49)  # 30-49%: 10%\n\ndef generate_evaluation_sample():\n    \"\"\"\n    ë‹¨ì¼ í‰ê°€ ìƒ˜í”Œ ìƒì„± (instruction-input-output)\n    \"\"\"\n    # ëœë¤í•˜ê²Œ IT ë„ë©”ì¸ ì„ íƒ\n    domain = random.choice(IT_DOMAINS)\n    project_type = random.choice(PROJECT_TYPES[domain])\n    \n    # í‰ê°€ ìœ í˜• ì„ íƒ (ë¹„ìœ¨ì— ë”°ë¼)\n    rand = random.random()\n    cumulative = 0\n    eval_type = None\n    for et, info in EVALUATION_TYPES.items():\n        cumulative += info['ë¹„ìœ¨']\n        if rand < cumulative:\n            eval_type = et\n            break\n    \n    if eval_type is None:\n        eval_type = \"ì „ì²´_í‰ê°€\"\n    \n    max_score = EVALUATION_TYPES[eval_type]['ë§Œì ']\n    eval_description = EVALUATION_TYPES[eval_type]['ì„¤ëª…']\n    \n    # ì ìˆ˜ ìƒì„±\n    score_ratio = generate_score_by_distribution()\n    target_score = int(max_score * score_ratio)\n    \n    # GPTì—ê²Œ RFP ìš”êµ¬ì‚¬í•­ + ì œì•ˆì„œ ë‚´ìš© + í‰ê°€ ìƒì„± ìš”ì²­\n    prompt = f\"\"\"\në‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ì œì•ˆì„œ í‰ê°€ ë°ì´í„° ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\në‹¤ìŒ ì¡°ê±´ìœ¼ë¡œ í‰ê°€ ìƒ˜í”Œì„ ìƒì„±í•´ì£¼ì„¸ìš”:\n\n**í”„ë¡œì íŠ¸ ì •ë³´:**\n- IT ë„ë©”ì¸: {domain}\n- í”„ë¡œì íŠ¸ ìœ í˜•: {project_type}\n\n**í‰ê°€ ì •ë³´:**\n- í‰ê°€ í•­ëª©: {eval_type}\n- í‰ê°€ ì„¤ëª…: {eval_description}\n- ëª©í‘œ ì ìˆ˜: {target_score}/{max_score}ì \n\n**ìƒì„±í•  ë‚´ìš©:**\n1. **RFP ìš”êµ¬ì‚¬í•­**: {project_type}ì— ëŒ€í•œ í˜„ì‹¤ì ì¸ ìš”êµ¬ì‚¬í•­ (2-3ë¬¸ì¥)\n2. **ì œì•ˆì„œ ë‚´ìš©**: ìœ„ RFPì— ëŒ€í•œ ì œì•ˆì„œ ë‚´ìš© (2-3ë¬¸ì¥)\n   - {target_score}/{max_score}ì ì„ ë°›ì„ ë§Œí•œ ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±\n   - ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ë¬¸ì œì  í¬í•¨, ë†’ìœ¼ë©´ ìš°ìˆ˜í•œ ë‚´ìš© í¬í•¨\n3. **í‰ê°€ ì½”ë©˜íŠ¸**: RFP ìš”êµ¬ì‚¬í•­ ëŒ€ë¹„ ì œì•ˆì„œì˜ ì¶©ì¡±ë„ í‰ê°€ (2-3ë¬¸ì¥)\n   - êµ¬ì²´ì ì¸ ê·¼ê±° ì œì‹œ\n   - {eval_description} ê´€ì ì—ì„œ í‰ê°€\n\n**ì¶œë ¥ í˜•ì‹ (JSON):**\n{{\n  \"rfp_ìš”êµ¬ì‚¬í•­\": \"RFP ìš”êµ¬ì‚¬í•­ ë‚´ìš©\",\n  \"ì œì•ˆì„œ_ë‚´ìš©\": \"ì œì•ˆì„œ ë‚´ìš©\",\n  \"ì ìˆ˜\": {target_score},\n  \"ì½”ë©˜íŠ¸\": \"í‰ê°€ ì½”ë©˜íŠ¸\"\n}}\n\n**ì¤‘ìš” ì œì•½:**\n1. ì ìˆ˜ëŠ” ì •í™•íˆ {target_score}ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (ë§Œì : {max_score}ì )\n2. RFPì™€ ì œì•ˆì„œëŠ” ì„œë¡œ ì—°ê´€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤\n3. í‰ê°€ ì½”ë©˜íŠ¸ëŠ” RFP ìš”êµ¬ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤\n4. IT ë„ë©”ì¸({domain})ì— ë§ëŠ” í˜„ì‹¤ì ì¸ ë‚´ìš©ì´ì–´ì•¼ í•©ë‹ˆë‹¤\n5. ëª¨ë“  ë‚´ìš©ì€ ê²©ì‹ ìˆëŠ” ì œì•ˆì„œ ë¬¸ì²´ë¡œ ì‘ì„±í•˜ì„¸ìš”\n\"\"\"\n\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"ë‹¹ì‹ ì€ IT í”„ë¡œì íŠ¸ ì œì•ˆì„œ í‰ê°€ ë°ì´í„° ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•©ë‹ˆë‹¤.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.8,\n            response_format={\"type\": \"json_object\"}\n        )\n        \n        result = json.loads(response.choices[0].message.content)\n        \n        # instruction-input-output í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n        if eval_type == \"ì „ì²´_í‰ê°€\":\n            input_text = f\"[RFP ìš”êµ¬ì‚¬í•­]\\n{result['rfp_ìš”êµ¬ì‚¬í•­']}\\n\\n[ì œì•ˆì„œ ë‚´ìš©]\\n{result['ì œì•ˆì„œ_ë‚´ìš©']}\"\n        else:\n            input_text = f\"[í‰ê°€ í•­ëª©] {eval_type} (ë§Œì : {max_score}ì )\\n[RFP ìš”êµ¬ì‚¬í•­]\\n{result['rfp_ìš”êµ¬ì‚¬í•­']}\\n\\n[ì œì•ˆì„œ ë‚´ìš©]\\n{result['ì œì•ˆì„œ_ë‚´ìš©']}\"\n        \n        return {\n            \"instruction\": \"ì‹¬ì‚¬ ê¸°ì¤€í‘œì— ë§ì¶° í‰ê°€ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•˜ì‹œì˜¤.\",\n            \"input\": input_text,\n            \"output\": f\"[ì ìˆ˜] {result['ì ìˆ˜']}/{max_score}\\n[ì½”ë©˜íŠ¸] {result['ì½”ë©˜íŠ¸']}\"\n        }\n    \n    except Exception as e:\n        print(f\"ìƒ˜í”Œ ìƒì„± ì‹¤íŒ¨: {e}\")\n        return None\n\nprint(\"âœ… í‰ê°€ ìƒ˜í”Œ ìƒì„± í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ìƒì„± ë©”ì¸ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_dataset(num_samples=5000):\n",
    "    \"\"\"\n",
    "    í‰ê°€ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        num_samples: ìƒì„±í•  ìƒ˜í”Œ ìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"í‰ê°€ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘: {num_samples}ê°œ ìƒ˜í”Œ\")\n",
    "    print(f\"ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {num_samples * 0.8 / 60:.0f}-{num_samples * 1.2 / 60:.0f}ë¶„\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    samples = []\n",
    "    failed_count = 0\n",
    "    \n",
    "    for i in tqdm(range(num_samples), desc=\"ìƒ˜í”Œ ìƒì„± ì¤‘\"):\n",
    "        sample = generate_evaluation_sample()\n",
    "        \n",
    "        if sample is not None:\n",
    "            samples.append(sample)\n",
    "        else:\n",
    "            failed_count += 1\n",
    "        \n",
    "        # ì¤‘ê°„ ì €ì¥ (1000ê°œë§ˆë‹¤)\n",
    "        if (i + 1) % 1000 == 0 and len(samples) > 0:\n",
    "            temp_filename = f\"{OUTPUT_DIR}/evaluation_dataset_temp_{i+1}.jsonl\"\n",
    "            with open(temp_filename, 'w', encoding='utf-8') as f:\n",
    "                start_idx = max(0, len(samples) - 1000)\n",
    "                for s in samples[start_idx:]:\n",
    "                    f.write(json.dumps(s, ensure_ascii=False) + '\\n')\n",
    "            print(f\"\\nâœ… ì¤‘ê°„ ì €ì¥: {temp_filename} ({len(samples)}ê°œ ì™„ë£Œ)\")\n",
    "    \n",
    "    # ìµœì¢… ì €ì¥\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"{OUTPUT_DIR}/evaluation_dataset_{num_samples}_{timestamp}.jsonl\"\n",
    "    \n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        for sample in samples:\n",
    "            f.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"âœ… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "    print(f\"  - ì„±ê³µ: {len(samples)}ê°œ\")\n",
    "    print(f\"  - ì‹¤íŒ¨: {failed_count}ê°œ\")\n",
    "    print(f\"  - ì¶œë ¥ íŒŒì¼: {output_filename}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ ìƒì„± ë©”ì¸ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤í–‰\n",
    "\n",
    "â±ï¸ **ì˜ˆìƒ ì†Œìš” ì‹œê°„:**\n",
    "- 100ê°œ: ì•½ 1-2ë¶„\n",
    "- 1,000ê°œ: ì•½ 13-20ë¶„\n",
    "- 5,000ê°œ: ì•½ 67-100ë¶„\n",
    "- 10,000ê°œ: ì•½ 133-200ë¶„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ìƒì„± ì‹¤í–‰\n",
    "#\n",
    "# ğŸ’¡ ì²˜ìŒ ì‹¤í–‰ ì‹œ ê¶Œì¥: num_samples=100 (í…ŒìŠ¤íŠ¸ìš©, 1-2ë¶„)\n",
    "#\n",
    "# ê¶Œì¥ ì„¤ì •:\n",
    "# - í…ŒìŠ¤íŠ¸: num_samples=100 (1-2ë¶„) â­ ë¨¼ì € ì´ê²ƒë¶€í„°!\n",
    "# - ìµœì†Œ: num_samples=1000 (13-20ë¶„)\n",
    "# - ê¶Œì¥: num_samples=5000 (67-100ë¶„)\n",
    "# - ì´ìƒì : num_samples=10000 (133-200ë¶„)\n",
    "\n",
    "samples = generate_evaluation_dataset(num_samples=100)  # â¬…ï¸ ì²˜ìŒì—” 100ìœ¼ë¡œ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ê²€ì¦ ë° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ JSONL íŒŒì¼ ë¡œë“œ\n",
    "import glob\n",
    "\n",
    "jsonl_files = sorted(glob.glob(f\"{OUTPUT_DIR}/evaluation_dataset_*.jsonl\"))\n",
    "\n",
    "if jsonl_files:\n",
    "    # temp íŒŒì¼ ì œì™¸í•˜ê³  ìµœì‹  íŒŒì¼ ì„ íƒ\n",
    "    main_files = [f for f in jsonl_files if 'temp' not in f]\n",
    "    latest_file = main_files[-1] if main_files else jsonl_files[-1]\n",
    "    \n",
    "    print(f\"ìµœì‹  ë°ì´í„°ì…‹ íŒŒì¼: {latest_file}\\n\")\n",
    "    \n",
    "    # ìƒ˜í”Œ ë¡œë“œ\n",
    "    samples = []\n",
    "    with open(latest_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            samples.append(json.loads(line))\n",
    "    \n",
    "    print(f\"ì´ ìƒ˜í”Œ ìˆ˜: {len(samples)}ê°œ\\n\")\n",
    "    \n",
    "    # ìƒ˜í”Œ 5ê°œ ì¶œë ¥\n",
    "    print(\"=== ìƒ˜í”Œ ì˜ˆì‹œ ===\")\n",
    "    for i, sample in enumerate(samples[:5], 1):\n",
    "        print(f\"\\n[ìƒ˜í”Œ {i}]\")\n",
    "        print(f\"Instruction: {sample['instruction']}\")\n",
    "        print(f\"Input: {sample['input'][:150]}...\")\n",
    "        print(f\"Output: {sample['output']}\")\n",
    "    \n",
    "    # ì ìˆ˜ ë¶„í¬ ë¶„ì„\n",
    "    print(\"\\n=== ì ìˆ˜ ë¶„í¬ ë¶„ì„ ===\")\n",
    "    scores = []\n",
    "    for sample in samples:\n",
    "        output = sample['output']\n",
    "        if '[ì ìˆ˜]' in output:\n",
    "            score_part = output.split('[ì ìˆ˜]')[1].split('[ì½”ë©˜íŠ¸]')[0].strip()\n",
    "            score_str = score_part.split('/')[0].strip()\n",
    "            try:\n",
    "                scores.append(int(score_str))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if scores:\n",
    "        from collections import Counter\n",
    "        score_ranges = {\n",
    "            \"90-100ì \": 0,\n",
    "            \"80-89ì \": 0,\n",
    "            \"70-79ì \": 0,\n",
    "            \"50-69ì \": 0,\n",
    "            \"30-49ì \": 0,\n",
    "            \"0-29ì \": 0\n",
    "        }\n",
    "        \n",
    "        for score in scores:\n",
    "            if 90 <= score <= 100:\n",
    "                score_ranges[\"90-100ì \"] += 1\n",
    "            elif 80 <= score <= 89:\n",
    "                score_ranges[\"80-89ì \"] += 1\n",
    "            elif 70 <= score <= 79:\n",
    "                score_ranges[\"70-79ì \"] += 1\n",
    "            elif 50 <= score <= 69:\n",
    "                score_ranges[\"50-69ì \"] += 1\n",
    "            elif 30 <= score <= 49:\n",
    "                score_ranges[\"30-49ì \"] += 1\n",
    "            else:\n",
    "                score_ranges[\"0-29ì \"] += 1\n",
    "        \n",
    "        total = len(scores)\n",
    "        for range_name, count in score_ranges.items():\n",
    "            percentage = (count / total * 100) if total > 0 else 0\n",
    "            bar = 'â–ˆ' * int(percentage / 2)\n",
    "            print(f\"{range_name:15s}: {bar} {count:4d}ê°œ ({percentage:5.1f}%)\")\n",
    "        \n",
    "        print(f\"\\ní‰ê·  ì ìˆ˜: {sum(scores)/len(scores):.1f}\")\n",
    "        print(f\"ìµœê³  ì ìˆ˜: {max(scores)}\")\n",
    "        print(f\"ìµœì € ì ìˆ˜: {min(scores)}\")\n",
    "        \n",
    "        # ëª©í‘œ ëŒ€ë¹„ ì‹¤ì œ ë¶„í¬\n",
    "        print(f\"\\n=== ëª©í‘œ ëŒ€ë¹„ ì‹¤ì œ ë¶„í¬ ===\")\n",
    "        print(f\"90-100ì : ëª©í‘œ 15% / ì‹¤ì œ {score_ranges['90-100ì ']/total*100:.1f}%\")\n",
    "        print(f\"80-89ì :  ëª©í‘œ 25% / ì‹¤ì œ {score_ranges['80-89ì ']/total*100:.1f}%\")\n",
    "        print(f\"70-79ì :  ëª©í‘œ 30% / ì‹¤ì œ {score_ranges['70-79ì ']/total*100:.1f}%\")\n",
    "        print(f\"50-69ì :  ëª©í‘œ 20% / ì‹¤ì œ {score_ranges['50-69ì ']/total*100:.1f}%\")\n",
    "        print(f\"30-49ì :  ëª©í‘œ 10% / ì‹¤ì œ {score_ranges['30-49ì ']/total*100:.1f}%\")\n",
    "else:\n",
    "    print(\"ìƒì„±ëœ ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIP íŒŒì¼ë¡œ ì••ì¶•\n",
    "import shutil\n",
    "\n",
    "zip_filename = \"evaluation_dataset\"\n",
    "shutil.make_archive(zip_filename, 'zip', OUTPUT_DIR)\n",
    "print(f\"\\nâœ… ì••ì¶• ì™„ë£Œ: {zip_filename}.zip\")\n",
    "\n",
    "# êµ¬ê¸€ ì½”ë©ì—ì„œ ë‹¤ìš´ë¡œë“œ\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(f\"{zip_filename}.zip\")\n",
    "    print(\"ë‹¤ìš´ë¡œë“œ ì‹œì‘!\")\n",
    "except ImportError:\n",
    "    print(\"ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}